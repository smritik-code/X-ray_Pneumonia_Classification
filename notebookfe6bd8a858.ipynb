{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1454699,"sourceType":"datasetVersion","datasetId":852810}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T06:27:58.443820Z","iopub.execute_input":"2025-11-23T06:27:58.444234Z","iopub.status.idle":"2025-11-23T06:28:05.596403Z","shell.execute_reply.started":"2025-11-23T06:27:58.444209Z","shell.execute_reply":"2025-11-23T06:28:05.595601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2 as cv\nimport numpy as np\nimport os\nimport random\n\ntrain_normal= \"/kaggle/input/chestxraydataset/chest_xray/train/NORMAL/\"\ntrain_pneumonia= \"/kaggle/input/chestxraydataset/chest_xray/train/PNEUMONIA/\"\n\ntest_normal= \"/kaggle/input/chestxraydataset/chest_xray/test/NORMAL/\"\ntest_pneumonia= \"/kaggle/input/chestxraydataset/chest_xray/test/PNEUMONIA/\"\n\n\ndef augment_img_pos(image):\n  rows,cols,_ = image.shape # height, width, RGB \n  # cols-1 and rows-1 are the coordinate limits.\n  M = cv.getRotationMatrix2D(center=((cols-1)/2.0,(rows-1)/2.0),angle=10,scale=1)\n  dst = cv.warpAffine(image,M,dsize=(cols,rows))\n\n  # create the translation matrix using tx and ty, it is a NumPy array \n  translation_M = np.array([\n      [1, 0, 10],\n      [0, 1, 15]\n  ], dtype=np.float32)\n  dst = cv.warpAffine(dst,translation_M,dsize=(cols,rows))\n\n  return dst\n\ndef augment_img_neg(image):\n  rows,cols,_ = image.shape # row, col, RGB \n  # cols-1 and rows-1 are the coordinate limits.\n  M = cv.getRotationMatrix2D(center=((cols-1)/2.0,(rows-1)/2.0),angle=-10,scale=1)\n  dst = cv.warpAffine(image,M,dsize=(cols,rows))\n\n  # create the translation matrix using tx and ty, it is a NumPy array \n  translation_M = np.array([\n      [1, 0, -5],\n      [0, 1, -20]\n  ], dtype=np.float32)\n  dst = cv.warpAffine(dst,translation_M,dsize=(cols,rows))\n  \n  return dst\n\ntrain_folders = [train_normal, train_pneumonia]\n\noutput_base = \"/kaggle/working/train/\"\noutput_normal = os.path.join(output_base, \"NORMAL\")\noutput_pneumonia = os.path.join(output_base, \"PNEUMONIA\")\n\nos.makedirs(output_normal, exist_ok=True)\nos.makedirs(output_pneumonia, exist_ok=True)\n\n# Loop over each folder\nfor folder_path in train_folders:\n    # Get all image files in the folder\n    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n    \n    # Shuffle images randomly\n    random.shuffle(image_files)\n    \n    # Determine number of images to augment (30% of total)\n    num_to_augment = int(len(image_files) * 0.3)\n    half_aug = num_to_augment // 2  # 15% for pos, 15% for neg\n    \n    # Split the selected images for positive and negative augmentation\n    pos_images = image_files[:half_aug]\n    neg_images = image_files[half_aug:num_to_augment]\n    \n    # --- Positive augmentation ---\n    for img_file in pos_images:\n        img_path = os.path.join(folder_path, img_file)\n        img = cv.imread(img_path)\n        aug_img = augment_img_pos(img)\n        \n        # Create new filename\n        base_name, ext = os.path.splitext(img_file)\n        new_name = f\"{base_name}_pos{ext}\"\n        save_folder = output_normal if folder_path == train_normal else output_pneumonia\n        cv.imwrite(os.path.join(save_folder, new_name), aug_img)\n    \n    # --- Negative augmentation ---\n    for img_file in neg_images:\n        img_path = os.path.join(folder_path, img_file)\n        img = cv.imread(img_path)\n        aug_img = augment_img_neg(img)\n        \n        # Create new filename\n        base_name, ext = os.path.splitext(img_file)\n        new_name = f\"{base_name}_neg{ext}\"\n        save_folder = output_normal if folder_path == train_normal else output_pneumonia\n        cv.imwrite(os.path.join(save_folder, new_name), aug_img)\n    \n    print(f\"Augmented {num_to_augment} images ({half_aug} pos, {half_aug} neg)\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T06:28:05.597846Z","iopub.execute_input":"2025-11-23T06:28:05.598179Z","iopub.status.idle":"2025-11-23T06:28:52.161663Z","shell.execute_reply.started":"2025-11-23T06:28:05.598160Z","shell.execute_reply":"2025-11-23T06:28:52.161062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(img, target_size=(224,224)):\n    # Histogram Equalization for contrast\n    image_bw = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n    clahe = cv.createCLAHE(clipLimit=4)\n    clahe_img = np.clip(clahe.apply(image_bw) + 30, 0, 255).astype(np.uint8)\n    clahe_rgb = cv.cvtColor(clahe_img, cv.COLOR_GRAY2BGR)\n    \n    img_resized = cv.resize(clahe_rgb, dsize=target_size, interpolation=cv.INTER_CUBIC)\n    img_normalized = img_resized / 255.0\n    return img_normalized\n\ntrain_normal= \"/kaggle/working/train/NORMAL/\"\ntrain_pneumonia= \"/kaggle/working/train/PNEUMONIA/\"\ntrain_folders = [train_normal, train_pneumonia]\n\nlabel_map = {train_normal: 0, train_pneumonia: 1}\n\nX_train = []\ny_train = []\n\n\n\nfor folder_path in train_folders:\n    label = label_map[folder_path]\n    \n    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n    \n    for img_file in image_files:\n        img_path = os.path.join(folder_path, img_file)\n        img = cv.imread(img_path)\n        \n        if img is None:\n            continue  # skip if reading fails\n        \n        img_processed = preprocess_image(img)\n        \n        X_train.append(img_processed)\n        y_train.append(label)\n\nX_train = np.array(X_train, dtype=np.float32)\ny_train = np.array(y_train, dtype=np.int64)\n\nprint(\"Training data shape:\", X_train.shape)\nprint(\"Labels shape:\", y_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T06:28:52.162341Z","iopub.execute_input":"2025-11-23T06:28:52.162512Z","iopub.status.idle":"2025-11-23T06:29:13.718755Z","shell.execute_reply.started":"2025-11-23T06:28:52.162497Z","shell.execute_reply":"2025-11-23T06:29:13.718083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torchvision.models as models\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport time\n\nX = torch.tensor(X_train).permute(0,3,1,2).float()  # reaarange dimensions to (N,C,H,W)\ny = torch.tensor(y_train).long()\n\nX_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n\ntrain_dataset = TensorDataset(X_tr, y_tr)\nval_dataset   = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet50(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False  # freeze base layers\n\nnum_classes = 2\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-4)\n\n# 3. Train classifier head only\nnum_epochs_head = 9\nprint(\"=== Training classifier head ===\")\nfor epoch in range(num_epochs_head):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs_head}]\")\n    for imgs, labels in loop:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * imgs.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        loop.set_postfix(loss=loss.item(), acc=f\"{(preds==labels).sum().item()/imgs.size(0):.4f}\")\n    \n    epoch_loss = running_loss / total\n    epoch_acc  = correct / total\n    elapsed = time.time() - start_time\n    \n    # Validation\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * imgs.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n    val_loss /= val_total\n    val_acc = val_correct / val_total\n    \n    print(f\"[Head] Epoch {epoch+1}/{num_epochs_head} | \"\n          f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f} | Time: {elapsed:.1f}s\")\n\n# 4. Fine-tune Layer4 + classifier\nfor name, param in model.named_parameters():\n    if \"layer4\" in name or \"fc\" in name:\n        param.requires_grad = True\n\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n\nnum_epochs_finetune = 3\nprint(\"=== Fine-tuning last block + classifier ===\")\nfor epoch in range(num_epochs_finetune):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    start_time = time.time()\n    \n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs_finetune}]\")\n    for imgs, labels in loop:\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * imgs.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        loop.set_postfix(loss=loss.item(), acc=f\"{(preds==labels).sum().item()/imgs.size(0):.4f}\")\n    \n    epoch_loss = running_loss / total\n    epoch_acc  = correct / total\n    elapsed = time.time() - start_time\n    \n    # Validation\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * imgs.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n    val_loss /= val_total\n    val_acc = val_correct / val_total\n    \n    print(f\"[Fine-tune] Epoch {epoch+1}/{num_epochs_finetune} | \"\n          f\"Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f} | Time: {elapsed:.1f}s\")\n\n# 5. Save model\ntorch.save(model.state_dict(), \"resnet50_xray_finetuned.pth\")\nprint(\"Model saved as resnet50_xray_finetuned.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T06:29:13.719593Z","iopub.execute_input":"2025-11-23T06:29:13.719839Z","iopub.status.idle":"2025-11-23T06:30:05.873396Z","shell.execute_reply.started":"2025-11-23T06:29:13.719810Z","shell.execute_reply":"2025-11-23T06:30:05.872664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = \"resnet50_xray_finetuned.pth\"\ntorch.save(model.state_dict(), path)\n\nfrom IPython.display import FileLink\nFileLink(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T06:33:21.957803Z","iopub.execute_input":"2025-11-23T06:33:21.958124Z","iopub.status.idle":"2025-11-23T06:33:22.192793Z","shell.execute_reply.started":"2025-11-23T06:33:21.958099Z","shell.execute_reply":"2025-11-23T06:33:22.192022Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null}]}